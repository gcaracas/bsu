{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment a - Linguistics\n",
    "\n",
    "## Boise State University NLP - Dr. Kennington\n",
    "\n",
    "### Instructions and Hints:\n",
    "\n",
    "* For this assignment, we will be looking at tokenization, morphology, and syntax. \n",
    "* This will follow in a similar way as the notebook we did in class, though it will be a bit more work. \n",
    "* Answer each question (or, in some cases, follow the command)\n",
    "* Follow the instructions on the corresponding assignment Trello card for submitting your assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We will be using **[Tamarian](https://www.youtube.com/watch?v=ANvlLcOTy6M)** as our example language: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'Sinda his face black his eyes red',\n",
    "    'Tamak',\n",
    "    'The river Tamak in winter',\n",
    "    'Darmok and Jalad at Tanagra',\n",
    "    'Darmok and Jalad on the ocean',\n",
    "    'Socath his eyes opened',\n",
    "#    'The beast of Tanagra Usani his army Jakka when the walls fell', # don't worry about this one\n",
    "    'Picard and Dathan at Eladrel',\n",
    "    'Marab with sails unfurled',\n",
    "    'Timba his arms open',\n",
    "    'Timba at rest'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Tokenize the sentences \n",
    "\n",
    "* you will need to make sure everything is lower case\n",
    "* you will need to represent the sentences as a 2D array of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = list(map(lambda x: x.lower().split(), sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Use a stemmer or lemmatizer \n",
    "\n",
    "- (NLTK has several) \n",
    "-  You will know your stemmer/lemmatizer did its job because plural words will no longer be plural (e.g., 'eyes' -> 'eye') and past-tense words will no longer be past-tense (e.g. 'unfurled' -> 'unfurl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "sentences = list(map(lambda x: [stemmer.stem(j) for j in x], sentences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a grammar that can parse all of the sentences\n",
    "\n",
    "* Try to write as few grammar rules as possible\n",
    "* Use recursion where you can\n",
    "* Use `S` as the start symbol\n",
    "* All terminals need to be in quotes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['sinda', 'hi', 'face', 'black', 'hi', 'eye', 'red'],\n",
       " ['tamak'],\n",
       " ['the', 'river', 'tamak', 'in', 'winter'],\n",
       " ['darmok', 'and', 'jalad', 'at', 'tanagra'],\n",
       " ['darmok', 'and', 'jalad', 'on', 'the', 'ocean'],\n",
       " ['socath', 'hi', 'eye', 'open'],\n",
       " ['picard', 'and', 'dathan', 'at', 'eladrel'],\n",
       " ['marab', 'with', 'sail', 'unfurl'],\n",
       " ['timba', 'hi', 'arm', 'open'],\n",
       " ['timba', 'at', 'rest']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sinda', 'hi', 'face', 'black', 'hi', 'eye', 'red']\n",
      "(S\n",
      "  (ADJP\n",
      "    (ADJP (NP (NP (N sinda) (P hi)) (N face)) (JJ black))\n",
      "    (ADJP (PP (P hi) (N eye)) (JJ red))))\n",
      "---------\n",
      "['tamak']\n",
      "(S (V tamak))\n",
      "---------\n",
      "['the', 'river', 'tamak', 'in', 'winter']\n",
      "(S\n",
      "  (VP (VP (NP (DT the) (N river)) (V tamak)) (PP (P in) (N winter))))\n",
      "---------\n",
      "['darmok', 'and', 'jalad', 'at', 'tanagra']\n",
      "(S\n",
      "  (NP\n",
      "    (NP (N darmok) (CC and))\n",
      "    (NP (NP (N jalad) (P at)) (N tanagra))))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NP (N darmok) (CC and)) (PP (N jalad) (P at)))\n",
      "    (N tanagra)))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NP (N darmok) (CC and)) (NP (N jalad) (P at)))\n",
      "    (N tanagra)))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NP (N darmok) (CC and)) (N jalad))\n",
      "    (PP (P at) (N tanagra))))\n",
      "(S (NP (NP (N darmok) (CC and)) (N jalad)) (PP (P at) (N tanagra)))\n",
      "---------\n",
      "['darmok', 'and', 'jalad', 'on', 'the', 'ocean']\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NP (N darmok) (CC and)) (PP (N jalad) (P on)))\n",
      "    (NP (DT the) (N ocean))))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NP (N darmok) (CC and)) (NP (N jalad) (P on)))\n",
      "    (NP (DT the) (N ocean))))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (N darmok) (CC and))\n",
      "    (NP (NP (N jalad) (P on)) (NP (DT the) (N ocean)))))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (N darmok) (CC and))\n",
      "    (NP (PP (N jalad) (P on)) (NP (DT the) (N ocean)))))\n",
      "(S\n",
      "  (N darmok)\n",
      "  (NP (PP (CC and) (PP (N jalad) (P on))) (NP (DT the) (N ocean))))\n",
      "---------\n",
      "['socath', 'hi', 'eye', 'open']\n",
      "(S (VP (NP (NP (N socath) (P hi)) (N eye)) (V open)))\n",
      "---------\n",
      "['picard', 'and', 'dathan', 'at', 'eladrel']\n",
      "(S\n",
      "  (NP\n",
      "    (NP (N picard) (CC and))\n",
      "    (NP (NP (N dathan) (P at)) (N eladrel))))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NP (N picard) (CC and)) (PP (N dathan) (P at)))\n",
      "    (N eladrel)))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NP (N picard) (CC and)) (NP (N dathan) (P at)))\n",
      "    (N eladrel)))\n",
      "(S\n",
      "  (NP\n",
      "    (NP (NP (N picard) (CC and)) (N dathan))\n",
      "    (PP (P at) (N eladrel))))\n",
      "(S (NP (NP (N picard) (CC and)) (N dathan)) (PP (P at) (N eladrel)))\n",
      "---------\n",
      "['marab', 'with', 'sail', 'unfurl']\n",
      "(S (VP (NP (NP (N marab) (P with)) (N sail)) (V unfurl)))\n",
      "---------\n",
      "['timba', 'hi', 'arm', 'open']\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Grammar does not cover some of the input words: \"'timba', 'arm'\".",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-426091941860>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mtree\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'---------'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Macintosh HD/projects/virtualEnvs/python3/lib/python3.7/site-packages/nltk/parse/chart.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, tokens, tree_class)\u001b[0m\n\u001b[1;32m   1489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1491\u001b[0;31m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchart_parse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1492\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchart\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparses\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree_class\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtree_class\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Macintosh HD/projects/virtualEnvs/python3/lib/python3.7/site-packages/nltk/parse/chart.py\u001b[0m in \u001b[0;36mchart_parse\u001b[0;34m(self, tokens, trace)\u001b[0m\n\u001b[1;32m   1447\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mtokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_coverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0mchart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chart_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m         \u001b[0mgrammar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_grammar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Volumes/Macintosh HD/projects/virtualEnvs/python3/lib/python3.7/site-packages/nltk/grammar.py\u001b[0m in \u001b[0;36mcheck_coverage\u001b[0;34m(self, tokens)\u001b[0m\n\u001b[1;32m    682\u001b[0m             \u001b[0mmissing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m', '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%r'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m             raise ValueError(\n\u001b[0;32m--> 684\u001b[0;31m                 \u001b[0;34m\"Grammar does not cover some of the \"\u001b[0m \u001b[0;34m\"input words: %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    685\u001b[0m             )\n\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Grammar does not cover some of the input words: \"'timba', 'arm'\"."
     ]
    }
   ],
   "source": [
    "tamarian_grammar = nltk.CFG.fromstring(\"\"\"\n",
    " S -> NP PP | ADJP | V | VP | N NP | NP\n",
    " NP -> N CC | NP N | NP PP | PP NP | N P | DT N | NP NP\n",
    " PP -> P N | N P | CC PP\n",
    " ADJP -> NP JJ | PP JJ | ADJP ADJP\n",
    " VP -> NP V |VP PP\n",
    " N -> 'face'|'sinda'|'darmok'|'jalad'|'tanagra'|'eye'|'river'|'winter'|'darmok'|'ocean'|'socath'|'picard'|'dathan'|'eladrel'|'marab'|'sail'|'timba'|'arm'\n",
    " P -> 'hi'|'at'|'in'|'on'|'with'\n",
    " CC -> 'and'\n",
    " JJ -> 'black'|'red'\n",
    " V -> 'tamak'|'open'|'unfurl'\n",
    " DT -> 'the'\n",
    "\"\"\")\n",
    "s = 'darmok and jalad at tanagra'.split()\n",
    "parser = nltk.ChartParser(tamarian_grammar)\n",
    "for s in sentences[0:9]:\n",
    "    print(s)\n",
    "    for tree in parser.parse(s):\n",
    "        print(tree)\n",
    "    print('---------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Show that your grammar parses all of the sentences\n",
    "\n",
    "* Use a parser that can use a CFG (NLTK has several) \n",
    "* Make sure there is a parse tree for each of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = nltk.ChartParser(tamarian_grammar)\n",
    "for tree in parser.parse(s):\n",
    "    print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sinda', 'hi', 'face', 'black', 'hi', 'eye', 'red']\n",
      "\n",
      "------------\n",
      "['tamak']\n",
      "\n",
      "------------\n",
      "['the', 'river', 'tamak', 'in', 'winter']\n",
      "\n",
      "------------\n",
      "['darmok', 'and', 'jalad', 'at', 'tanagra']\n",
      "\n",
      "------------\n",
      "['darmok', 'and', 'jalad', 'on', 'the', 'ocean']\n",
      "\n",
      "------------\n",
      "['socath', 'hi', 'eye', 'open']\n",
      "\n",
      "------------\n",
      "['picard', 'and', 'dathan', 'at', 'eladrel']\n",
      "\n",
      "------------\n",
      "['marab', 'with', 'sail', 'unfurl']\n",
      "\n",
      "------------\n",
      "['timba', 'hi', 'arm', 'open']\n",
      "\n",
      "------------\n",
      "['timba', 'at', 'rest']\n",
      "\n",
      "------------\n"
     ]
    }
   ],
   "source": [
    "parser = nltk.ChartParser(tamarian_grammar)\n",
    "for s in sentences:\n",
    "    print(s)\n",
    "    for tree in parser.parse(s):\n",
    "        print(tree)\n",
    "    print()\n",
    "    print('------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For questions 5-7, just answer in marktown/raw text. No code necessary.\n",
    "\n",
    "## 5. Does your parser have full coverage?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Does your parser over-generate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Which sentences are ambiguous? How do you know?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Parse this sentence:\n",
    "\n",
    "* If you wrote your grammar right, this should be covered. If this isn't covered, then you'll need to go back and change your grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['timba', 'his', 'face', 'red', 'his', 'eye', 'back', 'in', 'winter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Was your result in Questions 8 ambiguous?\n",
    "\n",
    "* Answer in markdown or raw text, no code necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 10. How expressive is your language?\n",
    "\n",
    "* Answer in markdown or raw text, no code necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(answer here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Make the grammar more general by treating POS tags as the terminals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tamarian_grammar = nltk.CFG.fromstring(\"\"\"\n",
    "    S   -> \n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. What is your set of POS tags?\n",
    "\n",
    "* show the list of strings (e.g., ['Adj', ...])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Make a list for the POS tags that correspond to the sentence `s` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ['timba', 'his', 'face', 'red', 'his', 'eye', 'back', 'in', 'winter']\n",
    "# p = ['PN',  ??, ... ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Parse the sentence (represented as POS tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Credit! Do all of the above questions again, but add the sentence:\n",
    "\n",
    "'The beast of Tanagra Usani his army Jakka when the walls fell'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "*Done!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('a4.ok')\n",
    "ok.auth(inline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok.submit()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
