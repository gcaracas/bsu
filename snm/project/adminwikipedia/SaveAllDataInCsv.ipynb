{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset source = http://snap.stanford.edu/data/wiki-RfA.html <br>\n",
    "Dataset title = \"Wikipedia Requests for Adminship (with text)\"<br>\n",
    "Dataset public = Yes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stats coming from dataset\n",
    "(median/mean: 19/34 tokens)<br>\n",
    "Nodes\t10,835<br>\n",
    "Edges\t159,388<br>\n",
    "Triangles\t956,428<br>\n",
    "Type of graph: Directed Signed Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset format\n",
    "*Fields*<br>\n",
    "SRC: user name of source, i.e., voter<br>\n",
    "TGT: user name of target, i.e., the user running for election<br>\n",
    "VOT: the source's vote on the target (-1 = oppose; 0 = neutral; 1 = support)<br>\n",
    "RES: the outcome of the election (-1 = target was rejected as admin; 1 = target was accepted)<br>\n",
    "YEA: the year in which the election was started<br>\n",
    "DAT: the date and time of this vote<br>\n",
    "TXT: the comment written by the source, in wiki markup<br>\n",
    "<br>\n",
    "<br>\n",
    "*Example*<br>\n",
    "SRC:Guettarda<br>\n",
    "TGT:Lord Roem<br>\n",
    "VOT:1<br>\n",
    "RES:1<br>\n",
    "YEA:2013<br>\n",
    "DAT:19:53, 25 January 2013<br>\n",
    "TXT:'''Support''' per [[WP:DEAL]]: clueful, and unlikely to break Wikipedia.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import  pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "from collections import Counter\n",
    "import pylab as plt\n",
    "from datascience import *\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate our indeces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "iSrc = 0\n",
    "iTgt = 1\n",
    "iVot = 2\n",
    "iRes = 3\n",
    "iTxt = 4\n",
    "iDat = 5\n",
    "iYea = 6\n",
    "iSrcId = 7\n",
    "iTgtId = 8\n",
    "iSrcInDegree = 9\n",
    "iSrcOutDegree = 10\n",
    "iTgtInDegree = 11\n",
    "iTgtOutDegree =12\n",
    "iNumWords = 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = \"./wiki-RfAv2.txt\"\n",
    "# Read file and save in content all the lines\n",
    "with open(file, mode=\"r\",encoding=\"utf-8\") as f:\n",
    "       content = f.read().splitlines()\n",
    "\n",
    "# We need a list of all the node's names\n",
    "# we will append into a list all the names, from src and tgt, so we can\n",
    "# include all of them\n",
    "srcTgtNodes = []\n",
    "for text in content:\n",
    "    textsp = re.split(r\":::\", text)\n",
    "    if textsp[0] == 'TGT' or textsp[0] == 'SRC':\n",
    "        srcTgtNodes.append(textsp[1])\n",
    "#fullTable = np.chararray((len(srcTgtNodes), 14))\n",
    "# Plust one for the column headers name\n",
    "r, c = 14, len(srcTgtNodes)+1\n",
    "\n",
    "iSrc = 0\n",
    "iTgt = 1\n",
    "iVot = 2\n",
    "iRes = 3\n",
    "iTxt = 4\n",
    "iDat = 5\n",
    "iYea = 6\n",
    "iSrcId = 7\n",
    "iTgtId = 8\n",
    "iSrcInDegree = 9\n",
    "iSrcOutDegree = 10\n",
    "iTgtInDegree = 11\n",
    "iTgtOutDegree =12\n",
    "iNumWords = 13\n",
    "\n",
    "fullTable = [[\" \" for x in range(r)] for y in range(c)] \n",
    "fullTable[0][0]=\"SRC\"\n",
    "fullTable[0][1]=\"TGT\"\n",
    "fullTable[0][2]=\"VOT\"\n",
    "fullTable[0][3]=\"RES\"\n",
    "fullTable[0][4]=\"TXT\"\n",
    "fullTable[0][5]=\"DAT\"\n",
    "fullTable[0][6]=\"YEA\"\n",
    "fullTable[0][7]=\"SRC_ID\"\n",
    "fullTable[0][8]=\"TGT_ID\"\n",
    "fullTable[0][9]=\"SRC_IN_DEGREE\"\n",
    "fullTable[0][10]=\"SRC_OUT_DEGREE\"\n",
    "fullTable[0][11]=\"TGT_IN_DEGREE\"\n",
    "fullTable[0][12]=\"TGT_OUT_DEGREE\"\n",
    "fullTable[0][13]=\"NUM_WORDS\"\n",
    "#Now that we have all the users, let's remove duplicates\n",
    "userSet = set(srcTgtNodes)\n",
    "usersDictionary = dict()\n",
    "a = enumerate(userSet)\n",
    "for k,v in a:\n",
    "    usersDictionary[v]=k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's setup the directed graph instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.DiGraph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's build the graph and also create the golbal list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check if all the fields are present\n",
    "DAT=\"\"\n",
    "RES=\"\"\n",
    "SRC=\"\"\n",
    "TGT=\"\"\n",
    "TXT=\"\"\n",
    "VOT=\"\"\n",
    "YEA=\"\"\n",
    "count = 0\n",
    "for text in content:\n",
    "    textsp = re.split(r\":::\", text)\n",
    "    if textsp[0] == 'VOT':\n",
    "        VOT=textsp[1]\n",
    "    if textsp[0] == 'YEA':\n",
    "        YEA=textsp[1]\n",
    "    if textsp[0] == 'DAT':\n",
    "        DAT=textsp[1]\n",
    "    if textsp[0] == 'RES':\n",
    "        RES=textsp[1]\n",
    "    if textsp[0] == 'SRC':\n",
    "        SRC=textsp[1]\n",
    "    if textsp[0] == 'TGT':\n",
    "        TGT=textsp[1]\n",
    "    if textsp[0] == 'TXT':\n",
    "        TXT=textsp[1]\n",
    "        # Now that we have all data per row, let's create node\n",
    "        G.add_edge(SRC, TGT)\n",
    "        G[SRC][TGT]['VOT'] = VOT\n",
    "        G[SRC][TGT]['RES'] = RES\n",
    "        G[SRC][TGT]['YEA'] = YEA\n",
    "        G[SRC][TGT]['DAT'] = DAT\n",
    "        G[SRC][TGT]['TXT'] = TXT\n",
    "        \n",
    "        \n",
    "        # Fill all fields for the big table\n",
    "        fullTable[count+1][iSrc]=SRC\n",
    "        fullTable[count+1][iTgt]=TGT\n",
    "        fullTable[count+1][iVot]=VOT\n",
    "        fullTable[count+1][iRes]=RES\n",
    "        fullTable[count+1][iTxt]=TXT\n",
    "        fullTable[count+1][iDat]=DAT\n",
    "        fullTable[count+1][iYea]=YEA\n",
    "        #fullTable[count][iSrcId]=\n",
    "        #fullTable[count][iTgtId]=\n",
    "        #fullTable[count][iSrcInDegree]=\n",
    "        #fullTable[count][iSrcOutDegree]=\n",
    "        #fullTable[count][iTgtInDegree]=\n",
    "        #fullTable[count][iTgtOutDegree]=\n",
    "        fullTable[count+1][iNumWords]=len((TXT).split())\n",
    "        \n",
    "        # Clean variables\n",
    "        DAT=\"\"\n",
    "        RES=\"\"\n",
    "        SRC=\"\"\n",
    "        TGT=\"\"\n",
    "        TXT=\"\"\n",
    "        VOT=\"\"\n",
    "        YEA=\"\"\n",
    "        \n",
    "        # Increase counter\n",
    "        count = count + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to convert first the tables we will use as numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "iSrc = 0\n",
    "iTgt = 1\n",
    "iVot = 2\n",
    "iRes = 3\n",
    "iTxt = 4\n",
    "iDat = 5\n",
    "iYea = 6\n",
    "iSrcId = 7\n",
    "iTgtId = 8\n",
    "iSrcInDegree = 9\n",
    "iSrcOutDegree = 10\n",
    "iTgtInDegree = 11\n",
    "iTgtOutDegree =12\n",
    "iNumWords = 13\n",
    "\"\"\"\n",
    "counter=0\n",
    "for a0, a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11, a12, a13 in fullTable:\n",
    "    if counter != 0:    \n",
    "        # Here we convert the user into its numerical representation\n",
    "        if a0 != ' ':\n",
    "            fullTable[counter][7] = usersDictionary[a0]\n",
    "        if a1 != ' ':\n",
    "            fullTable[counter][8] = usersDictionary[a1]\n",
    "        # Here we fill the in-degree and out-degree\n",
    "        fullTable[counter][9]=G.in_degree(a0)\n",
    "        fullTable[counter][10]=G.out_degree(a0)\n",
    "        fullTable[counter][11]=G.in_degree(a1)\n",
    "        fullTable[counter][12]=G.out_degree(a1)\n",
    "    counter=counter+1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"low_mem_data.csv\",\"w+\",encoding=\"utf-8\") as my_csv:\n",
    "    csvWriter = csv.writer(my_csv,delimiter=',')\n",
    "    csvWriter.writerows(fullTable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
